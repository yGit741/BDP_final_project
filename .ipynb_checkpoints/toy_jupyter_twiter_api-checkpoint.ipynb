{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "-jtisKAiCAFs",
   "metadata": {
    "id": "-jtisKAiCAFs"
   },
   "source": [
    "# Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ca47282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eafc25",
   "metadata": {},
   "source": [
    "Due to problems in interfacting with the API v2 (in v2 it allows only \"POST /2/tweets\", \"DELETE /2/tweets/:id\", \"GET /2/users/me\", and v1 was deprecated and did not work well), we wrote a script that sholud simulate creating the Kaggle data sheet.\n",
    "\n",
    "The folowing script doesn't work due to API limitations but should give a similar but not exact dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a3a606b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving tweets for BarackObama: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for justinbieber: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for katyperry: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for rihanna: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for realDonaldTrump: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for ladygaga: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for TheEllenShow: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for Cristiano: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for YouTube: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for jtimberlake: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for KimKardashian: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for britneyspears: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for Oprah: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for ArianaGrande: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for selenagomez: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for Twitter: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for taylorswift13: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for BillGates: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for narendramodi: 401 Unauthorized\n",
      "Unauthorized\n",
      "Error retrieving tweets for shakira: 401 Unauthorized\n",
      "Unauthorized\n"
     ]
    }
   ],
   "source": [
    "top_tweeters = [\n",
    "    \"BarackObama\", \"justinbieber\", \"katyperry\", \"rihanna\", \"realDonaldTrump\",\n",
    "    \"ladygaga\", \"TheEllenShow\", \"Cristiano\", \"YouTube\", \"jtimberlake\",\n",
    "    \"KimKardashian\", \"britneyspears\", \"Oprah\", \"ArianaGrande\", \"selenagomez\",\n",
    "    \"Twitter\", \"taylorswift13\", \"BillGates\", \"narendramodi\", \"shakira\"\n",
    "]\n",
    "\n",
    "# initialize a dictionary to store tweets of each tweeter\n",
    "tweets_dict = {\n",
    "    \"author\": [],\n",
    "    \"content\": [],\n",
    "    \"country\": [],\n",
    "    \"date_time\": [],\n",
    "    \"language\": [],\n",
    "    \"latitude\": [],\n",
    "    \"longitude\": [],\n",
    "    \"number_of_likes\": [],\n",
    "    \"number_of_shares\": []\n",
    "}\n",
    "\n",
    "# retrieve tweets of each tweeter for the year 2017\n",
    "for tweeter in top_tweeters:\n",
    "    try:\n",
    "        # Paginate through the user timeline to retrieve tweets\n",
    "        for tweet in api.get_users_tweets(id=tweeter, max_results=100):\n",
    "            if tweet.created_at.year == 2017:\n",
    "                tweets_dict[\"author\"].append(tweet.author.username)\n",
    "                tweets_dict[\"content\"].append(tweet.text)\n",
    "                tweets_dict[\"country\"].append(tweet.place.country if tweet.place else None)\n",
    "                tweets_dict[\"date_time\"].append(tweet.created_at)\n",
    "                tweets_dict[\"language\"].append(tweet.lang)\n",
    "                tweets_dict[\"latitude\"].append(tweet.geo.coordinates[0] if tweet.geo else None)\n",
    "                tweets_dict[\"longitude\"].append(tweet.geo.coordinates[1] if tweet.geo else None)\n",
    "                tweets_dict[\"number_of_likes\"].append(tweet.favorite_count)\n",
    "                tweets_dict[\"number_of_shares\"].append(tweet.retweet_count)\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving tweets for {tweeter}: {e}\")\n",
    "\n",
    "# create DataFrame from the collected tweets\n",
    "tweets_df = pd.DataFrame(tweets_dict)\n",
    "\n",
    "# save DataFrame to a CSV file\n",
    "# tweets_df.to_csv(\"tweets_df.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
